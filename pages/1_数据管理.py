import streamlit as st
import pandas as pd
import json
from services.db_service import get_conn
from services.data_loader import load_file, load_db
from pathlib import Path
from sqlalchemy import create_engine
from ydata_profiling import ProfileReport
from datetime import datetime
import secrets

st.set_page_config(layout="wide") # å¿…é¡»æ˜¯è¯¥é¡µé¢è„šæœ¬ä¸­çš„ç¬¬ä¸€ä¸ª Streamlit è°ƒç”¨


def sample_df(df: pd.DataFrame, frac=0.3, min_rows=1000, max_rows=5000, random_state=42):
    """
    å¯¹ DataFrame è¿›è¡Œé‡‡æ ·ï¼š
    - é»˜è®¤æŠ½å– frac çš„æ¯”ä¾‹ï¼Œä½†ä¸å°‘äº min_rowsï¼Œä¸å¤šäº max_rows
    """
    n_total = len(df)
    n_sample = min(max(int(n_total * frac), min_rows), max_rows, n_total)
    
    # éšæœºé‡‡æ ·
    df_sampled = df.sample(n=n_sample, random_state=random_state)
    return df_sampled

def generate_profile(df, data_name):
    """
    ä¸ºç»™å®šçš„ DataFrame ç”Ÿæˆäº¤äº’å¼æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Šï¼ˆHTML æ ¼å¼ï¼‰ï¼Œå¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚
    """
    profiling_dir = Path("data/profiling")
    profiling_dir.mkdir(parents=True, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
    file_path = profiling_dir / f"{data_name}.html"
    df_sampled = sample_df(df)
    profile = ProfileReport(df_sampled, title="Ignite Data Profiling", 
        minimal=True,      # True - ç¦ç”¨è€—æ—¶è®¡ç®—ï¼ˆå¦‚ç›¸å…³æ€§ã€æ ·æœ¬ã€é‡å¤è¡Œæ£€æµ‹ç­‰ï¼‰æŠ¥å‘Šç”Ÿæˆæ›´å¿« é€‚åˆå¤§æ•°æ®é›†æˆ–å¿«é€Ÿé¢„è§ˆ
        explorative=False, # å¯ç”¨æ›´æ·±å…¥çš„æ¢ç´¢ï¼ˆå¦‚æ–‡æœ¬åˆ†æã€URL/Email æ£€æµ‹ç­‰ï¼‰ï¼Œæ¯” minimal=False æ›´ç»†
        sensitive=False,   # è‹¥ä¸º Trueï¼Œä¼šå°è¯•æ£€æµ‹æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚èº«ä»½è¯ã€é“¶è¡Œå¡å·ï¼‰ï¼Œä½†å¯èƒ½è¯¯æŠ¥
        progress_bar=False)
    profile.to_file(file_path)
    return file_path


st.header("ğŸ“ æ•°æ®ç®¡ç†")
st.subheader("ğŸ”— æ•°æ®æºè¿æ¥")
tab1, tab2 = st.tabs(["ğŸ“‚ ä¸Šä¼ æ–‡ä»¶", "ğŸ—„ï¸ è¿æ¥æ•°æ®åº“"])

# ---------------- ä¸Šä¼ æ–‡ä»¶ ----------------
with tab1:
    uploaded = st.file_uploader("ä¸Šä¼  Excel / CSV", type=["csv", "xlsx"])
    if uploaded:
        df = load_file(uploaded)
        upload_id = secrets.token_urlsafe(6)  # ç”Ÿæˆ 8 å­—ç¬¦çš„çŸ­ IDï¼ˆçº¦ 48 ä½ç†µï¼Œå†²çªæ¦‚ç‡æä½ï¼‰ æ³¨æ„ï¼šå‚æ•°æ˜¯å­—èŠ‚æ•°ï¼Œä¸æ˜¯å­—ç¬¦æ•°ï¼
        safe_filename = f"{Path(uploaded.name).stem}_{upload_id}.csv"  # å°†æ•°æ®ä¿å­˜ä¸ºcsvæ ¼å¼
        save_path = Path("data/raw") / safe_filename
        df.to_csv(save_path, index=False)
        conn = get_conn()
        conn.execute(
            """INSERT INTO data_sources 
               (name, source_type, path, tag, upload_time) 
               VALUES (?, ?, ?, ?, ?)""",
            (uploaded.name, "file", str(save_path), "åŸæ•°æ®", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            )
        conn.commit()
        st.success("æ–‡ä»¶æ•°æ®æºå·²æ·»åŠ ")

# ---------------- æ•°æ®åº“ ----------------
with tab2:
    db_type = st.selectbox("æ•°æ®åº“ç±»å‹", ["sqlite", "mysql", "postgresql"])

    # å›ºå®šå‰ç¼€
    prefix_map = {
        "sqlite": "sqlite:///",
        "mysql": "mysql+pymysql://",
        "postgresql": "postgresql+psycopg2://"
    }
    fixed_prefix = prefix_map[db_type]

    # ç”¨æˆ·è¾“å…¥å‰©ä½™éƒ¨åˆ†
    user_input = st.text_input(
        "æ•°æ®åº“ä¿¡æ¯/æ–‡ä»¶è·¯å¾„ï¼šğŸ’¡SQLite: C:/path/to/db.db  |  MySQL/PostgreSQL: user:pass@host:port/dbname",
        placeholder="SQLite: C:/path/to/db.db | MySQL/PostgreSQL: user:pass@host:port/dbname [æŒ‰å›è½¦é”®åŠ è½½æ•°æ®]"
    )

    # æ‹¼æ¥å®Œæ•´è¿æ¥å­—ç¬¦ä¸²
    conn_str = fixed_prefix + user_input if user_input else None

    # åˆå§‹åŒ–è¡¨åˆ—è¡¨
    tables = []
    selected_table = None

    # è¿æ¥æ•°æ®åº“è·å–è¡¨åˆ—è¡¨
    if conn_str:
        try:
            engine = create_engine(conn_str)
            # SQLAlchemy 2.x ä½¿ç”¨ inspect
            from sqlalchemy import inspect
            inspector = inspect(engine)
            tables = inspector.get_table_names()

            if tables:
                st.success(f"æ‰¾åˆ° {len(tables)} å¼ è¡¨")
                selected_table = st.selectbox("é€‰æ‹©è¡¨", tables)
            else:
                st.warning("æ•°æ®åº“ä¸­æ²¡æœ‰è¡¨ï¼Œè¯·æ£€æŸ¥")
        except Exception as e:
            st.error(f"è¿æ¥å¤±è´¥: {e}")

    # å¯¼å…¥é€‰ä¸­è¡¨
    if selected_table and st.button("å¯¼å…¥è¡¨æ•°æ®"):
        try:
            df = pd.read_sql(f"SELECT * FROM {selected_table}", engine)
            st.success(f"æˆåŠŸå¯¼å…¥è¡¨: {selected_table}ï¼Œè¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")

            # åŒæ—¶å†™å…¥ä½ çš„ data_sources è¡¨
            conn = get_conn()
            conn.execute(
                """INSERT INTO data_sources 
                   (name, source_type, path, tag, upload_time) 
                   VALUES (?, ?, ?, ?, ?)""",
                (selected_table, db_type, conn_str, "åŸæ•°æ®", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            )
            conn.commit()

        except Exception as e:
            st.error(f"å¯¼å…¥å¤±è´¥: {e}")


st.markdown("")  # ç©ºä¸€è¡Œ

# ---------------- æ•°æ®æºåˆ—è¡¨ ----------------
st.subheader("ğŸ“‹ æ•°æ®æºåˆ—è¡¨")
st.markdown('<hr style="margin:8px 0; border-top: 1px solid #eee">', unsafe_allow_html=True)

conn = get_conn()
df_sources = pd.read_sql("SELECT * FROM data_sources ORDER BY id DESC", conn)

if df_sources.empty:
    st.info("è¿˜æ²¡æœ‰æ·»åŠ æ•°æ®æº")
else:    
    # è¡¨å¤´ï¼ˆä¿æŒå•è¡Œï¼‰
    col_widths_header = [0.5, 2, 1, 1, 1, 1]
    header_cols = st.columns(col_widths_header)
    header_texts = ["#", "File name", "File type", "Label", "Upload time", "Action"]
    for col, text in zip(header_cols, header_texts):
        col.markdown(f"**{text}**")

    st.markdown('<hr style="margin:1px 0; border-top: 2px solid #eee">', unsafe_allow_html=True)

    # éå†æ¯æ¡æ•°æ®æº
    for idx, row in df_sources.iterrows():
        # ===== ç¬¬ä¸€è¡Œï¼š# | æ–‡ä»¶å | ç±»å‹ | æ ‡ç­¾ | ä¸Šä¼ æ—¶é—´ | æ“ä½œ =====
        data_profiling_fn = f"{Path(row['name']).stem}_{row['id']}"
        row1_cols = st.columns(col_widths_header)  # ä¿æŒè·Ÿè¡¨å¤´ä¸€æ ·çš„åˆ—æ•°å’Œå®½åº¦
        with row1_cols[0]:
            st.write(idx + 1)
        with row1_cols[1]:
            st.write(row['name'])
        with row1_cols[2]:
            st.markdown(f"`{row['source_type']}`")
        with row1_cols[3]:
            st.write(row['tag'] if pd.notna(row['tag']) else "â€”")
        with row1_cols[4]:
            st.write(row['upload_time'])
        with row1_cols[5]:
            if st.button("åˆ é™¤", key=f"del_{row['id']}"):
                # åœ¨æ•°æ®åº“ä¸­åˆ é™¤æ•°æ®
                conn.execute("DELETE FROM data_sources WHERE id=?", (row["id"],))
                conn.commit()
                # åˆ é™¤ä¿å­˜çš„æ•°æ®æºæ–‡ä»¶
                raw_file = Path(row['path'])
                if raw_file.exists():
                    raw_file.unlink()
                # åˆ é™¤data profiling file
                html_file = Path(f"data/profiling/{data_profiling_fn}.html")
                if html_file.exists():
                    html_file.unlink()
                st.rerun()

        # ===== è¯»å–æ•°æ® =====
        try:
            if row["source_type"] == "file":
                df_file = pd.read_csv(row["path"])
            else:
                df_file = load_db(row["source_type"], row["path"], row["name"])
        except Exception as e:
            st.error(f"åŠ è½½å¤±è´¥: {e}")

        # ===== ç¬¬äºŒè¡Œï¼šæŸ¥çœ‹æ•°æ®æ ·æœ¬ =====
        with st.expander("ğŸ‘ï¸ View the sample(5)"):
            st.dataframe(df_file.head(), use_container_width=True)

        # ===== ç¬¬ä¸‰è¡Œï¼šæ±‡æ€»åˆ†æ =====
        with st.expander("ğŸ“Š Data profiling"):
            html_file = Path(f"data/profiling/{data_profiling_fn}.html")
            if df_file.empty:
                st.warning("No data in the file/table!")
            elif not html_file.exists():
                st.warning("æŠ¥å‘Šå°šæœªç”Ÿæˆï¼Œæ­£åœ¨ç”Ÿæˆä¸­...")
                html_file = generate_profile(df_file, data_profiling_fn)
                html_content = html_file.read_text(encoding="utf-8")
                st.components.v1.html(html_content, height=700, scrolling=True)
                st.download_button(
                    "ğŸ’¾ ä¸‹è½½ HTML æŠ¥å‘Š",
                    data=html_content,
                    file_name=html_file.name,
                    mime="text/html")
            else:
                html_content = html_file.read_text(encoding="utf-8")
                st.components.v1.html(html_content, height=700, scrolling=True)
                st.download_button(
                    "ğŸ’¾ ä¸‹è½½ HTML æŠ¥å‘Š",
                    data=html_content,
                    file_name=html_file.name,
                    mime="text/html")

        # æ¯æ¡æ•°æ®ååŠ åˆ†éš”çº¿
        st.markdown('<hr style="margin:1px 0; border-top: 1px solid #ddd">', unsafe_allow_html=True)
